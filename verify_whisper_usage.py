#!/usr/bin/env python3
"""
Verify that Whisper is actually being used (not Google)
"""

import os
import sys

# Add current directory to path
sys.path.insert(0, '.')

def verify_whisper_config():
    """Verify Whisper configuration and usage."""
    print("üîç Whisper Usage Verification")
    print("=" * 50)
    
    # Load environment
    try:
        from dotenv import load_dotenv
        load_dotenv()
        print("‚úÖ Environment loaded")
    except ImportError:
        print("‚ö†Ô∏è  python-dotenv not available")
    
    # Check environment variables
    speech_service = os.getenv("SPEECH_SERVICE", "google")
    openai_key = os.getenv("OPENAI_API_KEY")
    
    print(f"üìã Configuration:")
    print(f"   SPEECH_SERVICE: {speech_service}")
    print(f"   OPENAI_API_KEY: {'‚úÖ Set' if openai_key else '‚ùå Missing'}")
    
    if speech_service != "whisper":
        print(f"‚ùå ERROR: Speech service is '{speech_service}', not 'whisper'!")
        return False
    
    if not openai_key:
        print("‚ùå ERROR: OpenAI API key is missing!")
        return False
    
    print("‚úÖ Configuration looks correct for Whisper")
    print()
    
    # Test the actual implementation
    print("üß™ Testing actual speech recognition method...")
    
    try:
        from voice_to_suno_jbl import VoiceToSunoJBL
        
        # Create app instance
        app = VoiceToSunoJBL()
        
        # Check which method will be called
        print("üîç Checking speech recognition method selection...")
        
        # Create a dummy audio object for testing
        class DummyAudio:
            def __init__(self):
                self.sample_width = 2
                self.sample_rate = 16000
                self.frame_data = b'\x00' * 32000  # 1 second of silence
        
        dummy_audio = DummyAudio()
        
        # Test the method selection logic
        print(f"üìä Method selection test:")
        print(f"   SPEECH_SERVICE: {os.getenv('SPEECH_SERVICE')}")
        print(f"   OPENAI_API_KEY exists: {bool(os.getenv('OPENAI_API_KEY'))}")
        
        # This will show us which method gets called
        if os.getenv('SPEECH_SERVICE') == 'whisper' and os.getenv('OPENAI_API_KEY'):
            print("‚úÖ Will use: recognize_with_whisper()")
            
            # Test Whisper method directly
            print("\nüé§ Testing Whisper method directly...")
            try:
                result = app.recognize_with_whisper(dummy_audio)
                if result is not None:
                    print(f"‚úÖ Whisper method works! Result: '{result}'")
                    return True
                else:
                    print("‚ö†Ô∏è  Whisper method returned None (normal for silence)")
                    return True
            except Exception as e:
                print(f"‚ùå Whisper method failed: {e}")
                return False
        else:
            print("‚ùå Will use: recognize_with_google() (FALLBACK)")
            return False
            
    except Exception as e:
        print(f"‚ùå Import/setup error: {e}")
        return False

def test_live_whisper():
    """Test live Whisper recognition."""
    print("\nüé§ Live Whisper Test")
    print("=" * 30)
    print("This will record 5 seconds and process with Whisper")
    print("You should see 'Whisper:' in the output (not 'Google:')")
    print()
    
    try:
        from voice_to_suno_jbl import VoiceToSunoJBL
        
        app = VoiceToSunoJBL()
        
        choice = input("Ready to test live Whisper? (y/n): ")
        if not choice.lower().startswith('y'):
            print("üëã Test skipped")
            return
        
        print("üî¥ Recording 5 seconds for Whisper test...")
        
        # Modify the recording duration temporarily
        import speech_recognition as sr
        
        recognizer = sr.Recognizer()
        microphone = sr.Microphone()
        
        # Quick calibration
        with microphone as source:
            recognizer.adjust_for_ambient_noise(source, duration=1)
        
        # Record 5 seconds
        print("üé§ Speak now (5 seconds)...")
        with microphone as source:
            audio = recognizer.record(source, duration=5)
        
        print("üîÑ Processing with Whisper...")
        
        # Process with Whisper method directly
        result = app.recognize_with_whisper(audio)
        
        if result:
            print(f"‚úÖ WHISPER SUCCESS: '{result}'")
            print("üéâ Confirmed: Using OpenAI Whisper API!")
        else:
            print("‚ùå Whisper returned no result")
            
    except Exception as e:
        print(f"‚ùå Live test error: {e}")
        import traceback
        traceback.print_exc()

def main():
    """Main verification function."""
    print("üîç Whisper Usage Verification Tool")
    print("=" * 60)
    print("This will verify that Whisper (not Google) is being used.")
    print()
    
    # Step 1: Verify configuration
    config_ok = verify_whisper_config()
    
    if not config_ok:
        print("\n‚ùå Configuration issues found!")
        print("üí° Fix the configuration before proceeding")
        return
    
    print("\n‚úÖ Configuration verified - Whisper should be used!")
    
    # Step 2: Test live
    test_live_whisper()

if __name__ == "__main__":
    main()
